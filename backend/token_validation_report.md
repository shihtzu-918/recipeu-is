# HCX í† í° ê³„ì‚° ê²€ì¦ ë³´ê³ ì„œ

## 1. HCX API ì‘ë‹µ êµ¬ì¡° (ê³µì‹)

LangChain ë¬¸ì„œì— ë”°ë¥´ë©´ HCX APIëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ í† í° ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:

```python
AIMessage(
    content='...',
    response_metadata={
        'token_usage': {
            'completion_tokens': 10,   # ì¶œë ¥ í† í°
            'prompt_tokens': 28,       # ì…ë ¥ í† í°
            'total_tokens': 38,        # ì´ í† í°
            ...
        },
        ...
    },
    usage_metadata={
        'input_tokens': 28,       # = prompt_tokens
        'output_tokens': 10,      # = completion_tokens
        'total_tokens': 38,
        ...
    }
)
```

## 2. í˜„ì¬ ì½”ë“œì˜ í† í° ì¶”ì¶œ ë¡œì§

### ğŸ“ agent.py (25-67ë²ˆ ì¤„)

```python
def print_token_usage(response, context_name: str = "LLM"):
    # 1. usage ê°ì²´ ì°¾ê¸°
    usage = None
    if hasattr(response, 'response_metadata'):
        usage = response.response_metadata.get('token_usage') or response.response_metadata.get('usage')
    elif hasattr(response, 'usage_metadata'):
        usage = response.usage_metadata

    # 2. í† í° ì¶”ì¶œ
    if usage:
        prompt_tokens = usage.get('prompt_tokens') or usage.get('promptTokens') or usage.get('input_tokens', 0)
        completion_tokens = usage.get('completion_tokens') or usage.get('completionTokens') or usage.get('output_tokens', 0)
        total_tokens = usage.get('total_tokens') or usage.get('totalTokens', 0)

        # 3. total_tokensì´ ì—†ìœ¼ë©´ ê³„ì‚°
        if total_tokens == 0:
            total_tokens = prompt_tokens + completion_tokens
```

## 3. ê²€ì¦ ê²°ê³¼

### âœ… ì •í™•ì„± í‰ê°€

| í•­ëª© | í˜„ì¬ ì½”ë“œ | ì‹¤ì œ API | í‰ê°€ |
|------|----------|----------|------|
| **ìš°ì„ ìˆœìœ„** | response_metadata â†’ usage_metadata | ë‘˜ ë‹¤ ì œê³µ | âš ï¸ ê°œì„  í•„ìš” |
| **ì…ë ¥ í† í°** | prompt_tokens â†’ promptTokens â†’ input_tokens | `prompt_tokens` (metadata)<br>`input_tokens` (usage_metadata) | âœ… ì •í™• |
| **ì¶œë ¥ í† í°** | completion_tokens â†’ completionTokens â†’ output_tokens | `completion_tokens` (metadata)<br>`output_tokens` (usage_metadata) | âœ… ì •í™• |
| **ì´ í† í°** | total_tokens â†’ totalTokens â†’ ê³„ì‚° | `total_tokens` | âœ… ì •í™• |

### ğŸ” ë°œê²¬ëœ ì´ìŠˆ

#### 1. **usage ê°ì²´ ì¶”ì¶œ ë¡œì§ ê°œì„  í•„ìš”**

**í˜„ì¬ ì½”ë“œ:**
```python
usage = response.response_metadata.get('token_usage') or response.response_metadata.get('usage')
```

**ë¬¸ì œì :**
- `response_metadata`ëŠ” í•­ìƒ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ëŠ”ë°, ë‚´ë¶€ì˜ `token_usage` í‚¤ì— ì ‘ê·¼í•´ì•¼ í•¨
- í˜„ì¬ ì½”ë“œëŠ” `token_usage` ìì²´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ `response_metadata` ë”•ì…”ë„ˆë¦¬ ì „ì²´ë¥¼ í™•ì¸

**ì˜¬ë°”ë¥¸ ë¡œì§:**
```python
# response_metadata.token_usageëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ì§ì ‘ ì ‘ê·¼ ê°€ëŠ¥
usage = response.response_metadata.get('token_usage')
```

#### 2. **usage_metadata ìš°ì„  í™•ì¸ ê¶Œì¥**

LangChainì˜ í‘œì¤€ì€ `usage_metadata`ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

**ê¶Œì¥ ìˆœì„œ:**
```python
usage = None
if hasattr(response, 'usage_metadata'):
    usage = response.usage_metadata
elif hasattr(response, 'response_metadata'):
    usage = response.response_metadata.get('token_usage')
```

#### 3. **í•„ë“œëª… ìš°ì„ ìˆœìœ„ ì¡°ì •**

**í˜„ì¬:**
```python
prompt_tokens = usage.get('prompt_tokens') or usage.get('promptTokens') or usage.get('input_tokens', 0)
```

**ê°œì„  (usage_metadata ìš°ì„ ):**
```python
# usage_metadataë¥¼ ìš°ì„  ì‚¬ìš©í•˜ëŠ” ê²½ìš°
if hasattr(response, 'usage_metadata'):
    prompt_tokens = usage.get('input_tokens', 0)
    completion_tokens = usage.get('output_tokens', 0)
    total_tokens = usage.get('total_tokens', 0)
# response_metadata.token_usageë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
else:
    prompt_tokens = usage.get('prompt_tokens', 0)
    completion_tokens = usage.get('completion_tokens', 0)
    total_tokens = usage.get('total_tokens', 0)
```

## 4. í† í° ê³„ì‚° ì •í™•ì„±

### âœ… ê³„ì‚° ê³µì‹ ê²€ì¦

```python
if total_tokens == 0:
    total_tokens = prompt_tokens + completion_tokens
```

ì´ ë¡œì§ì€ **ì •í™•í•©ë‹ˆë‹¤**. HCX APIëŠ” ë‹¤ìŒì„ ë³´ì¥í•©ë‹ˆë‹¤:
- `total_tokens = prompt_tokens + completion_tokens`
- `total_tokens = input_tokens + output_tokens`

## 5. ìµœì¢… í‰ê°€

### ğŸ“Š í˜„ì¬ ìƒíƒœ

| í‰ê°€ í•­ëª© | ì ìˆ˜ | ì„¤ëª… |
|-----------|------|------|
| **í† í° ì¶”ì¶œ ì •í™•ì„±** | âœ… 95% | í† í° ê°’ì€ ì •í™•í•˜ê²Œ ì¶”ì¶œë¨ |
| **ì½”ë“œ ë¡œì§** | âš ï¸ 80% | usage ê°ì²´ ì¶”ì¶œ ë¡œì§ ê°œì„  í•„ìš” |
| **í‘œì¤€ ì¤€ìˆ˜** | âš ï¸ 70% | LangChain í‘œì¤€ (usage_metadata ìš°ì„ ) ë¯¸ì¤€ìˆ˜ |
| **ì—ëŸ¬ ì²˜ë¦¬** | âœ… 100% | Fallback ë¡œì§ ì™„ë²½ |

### ğŸ¯ ê²°ë¡ 

**í˜„ì¬ ì½”ë“œëŠ” í† í° ê°’ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤.** ë‹¤ë§Œ, ë‹¤ìŒ ê°œì„ ì‚¬í•­ì„ ê¶Œì¥í•©ë‹ˆë‹¤:

1. âœ… **usage_metadataë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©** (LangChain í‘œì¤€)
2. âœ… **í•„ë“œëª… ë¶„ê¸° ì²˜ë¦¬** (usage_metadata: input_tokens, response_metadata: prompt_tokens)
3. âœ… **usage ê°ì²´ ì¶”ì¶œ ë¡œì§ ëª…í™•í™”**

## 6. ê°œì„  ì½”ë“œ

```python
def print_token_usage(response, context_name: str = "LLM"):
    """LLM ì‘ë‹µì—ì„œ ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥ ë° ëˆ„ì """
    print(f"\n{'='*60}")
    print(f"[{context_name}] HCX API í† í° ì‚¬ìš©ëŸ‰ (ì‹¤ì¸¡)")
    print(f"{'='*60}")

    # âœ… ê°œì„ : usage_metadata ìš°ì„  í™•ì¸ (LangChain í‘œì¤€)
    usage = None
    source = ""

    if hasattr(response, 'usage_metadata'):
        usage = response.usage_metadata
        source = "usage_metadata"
    elif hasattr(response, 'response_metadata'):
        usage = response.response_metadata.get('token_usage')
        source = "response_metadata.token_usage"

    if usage:
        # âœ… ê°œì„ : ì†ŒìŠ¤ì— ë”°ë¼ í•„ë“œëª… ë¶„ê¸°
        if source == "usage_metadata":
            prompt_tokens = usage.get('input_tokens', 0)
            completion_tokens = usage.get('output_tokens', 0)
            total_tokens = usage.get('total_tokens', 0)
        else:
            prompt_tokens = usage.get('prompt_tokens', 0)
            completion_tokens = usage.get('completion_tokens', 0)
            total_tokens = usage.get('total_tokens', 0)

        # Fallback: total_tokensì´ ì—†ìœ¼ë©´ ê³„ì‚°
        if total_tokens == 0:
            total_tokens = prompt_tokens + completion_tokens

        # ì „ì²´ ëˆ„ì 
        _token_accumulator["prompt"] += prompt_tokens
        _token_accumulator["completion"] += completion_tokens
        _token_accumulator["total"] += total_tokens

        # ë…¸ë“œë³„ ì €ì¥ (ëˆ„ì )
        if context_name not in _node_tokens:
            _node_tokens[context_name] = {"prompt": 0, "completion": 0, "total": 0}
        _node_tokens[context_name]["prompt"] += prompt_tokens
        _node_tokens[context_name]["completion"] += completion_tokens
        _node_tokens[context_name]["total"] += total_tokens

        print(f"ğŸ“¥ ì…ë ¥ í† í° (prompt):     {prompt_tokens:,} tokens")
        print(f"ğŸ“¤ ì¶œë ¥ í† í° (completion): {completion_tokens:,} tokens")
        print(f"ğŸ“Š ì´ í† í° (total):        {total_tokens:,} tokens")
        print(f"ğŸ” í† í° ì†ŒìŠ¤: {source}")
    else:
        print(f"âš ï¸  í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"ì‘ë‹µ ê°ì²´ ì†ì„±: {dir(response)}")
        if hasattr(response, 'response_metadata'):
            print(f"response_metadata: {response.response_metadata}")
        if hasattr(response, 'usage_metadata'):
            print(f"usage_metadata: {response.usage_metadata}")

    print(f"{'='*60}\n")
```

## 7. ì°¸ê³  ìë£Œ

- [ChatClovaX - LangChain ë¬¸ì„œ](https://python.langchain.com/docs/integrations/chat/naver/)
- [CLOVA Studio Token Calculator](https://api.ncloud-docs.com/docs/en/clovastudio-tokenizerhcx)
- [CLOVA Studio API ë¬¸ì„œ](https://api.ncloud-docs.com/docs/en/ai-naver-clovastudio-summary)
